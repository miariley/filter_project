#Model Loss and Optimization 
#build the model 

import functools
import os

from matplotlib import gridspec
import IPython.display as display
import matplotlib.pylab as plt
import numpy as np
import PIL.Image
import tensorflow as tf
import tensorflow_hub as hub

#load vgg19 and choose intermediate layers 
vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')

print()
for layer in vgg.layers:
  print(layer.name)

user_layers = ['block5_conv2'] 

style_layers = ['block1_conv1',
                'block2_conv1',
                'block3_conv1', 
                'block4_conv1', 
                'block5_conv1']

num_user_layers = len(user_layers)
num_style_layers = len(style_layers)


def vgg_layers(layer_names):
  """ Creates a VGG model that returns a list of intermediate output values."""
  # Load our model. Load pretrained VGG, trained on ImageNet data
  vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
  vgg.trainable = False
  
  outputs = [vgg.get_layer(name).output for name in layer_names]

  model = tf.keras.Model([vgg.input], outputs)
  return model

user_image = loadimage('user_image.jpg')
style_image = loadimage('style_image.jpg')

style_extractor = vgg_layers(style_layers)
style_outputs = style_extractor(style_image*255)

#Look at the statistics of each layer's output
for name, output in zip(style_layers, style_outputs):
  print(name)
  print("  shape: ", output.numpy().shape)
  print("  min: ", output.numpy().min())
  print("  max: ", output.numpy().max())
  print("  mean: ", output.numpy().mean())
  print()

#calculate style 
def gram_matrix(input_tensor):
  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
  input_shape = tf.shape(input_tensor)
  num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
  return result/(num_locations)

class StyleContentModel(tf.keras.models.Model):
  def __init__(self, style_layers, user_layers):
    super(StyleContentModel, self).__init__()
    self.vgg = vgg_layers(style_layers + user_layers)
    self.style_layers = style_layers
    self.user_layers = user_layers
    self.num_style_layers = len(style_layers)
    self.vgg.trainable = False

  def call(self, inputs):
    "Expects float input in [0,1]"
    inputs = inputs*255.0
    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)
    outputs = self.vgg(preprocessed_input)
    style_outputs, user_outputs = (outputs[:self.num_style_layers],
                                      outputs[self.num_style_layers:])

    style_outputs = [gram_matrix(style_output)
                     for style_output in style_outputs]

    user_dict = {user_name: value
                    for user_name, value
                    in zip(self.user_layers, user_outputs)}

    style_dict = {style_name: value
                  for style_name, value
                  in zip(self.style_layers, style_outputs)}

    return {'user': user_dict, 'style': style_dict}

#extract style 

extractor = StyleContentModel(style_layers, user_layers)

results = extractor(tf.constant(user_image))

print('Styles:')
for name, output in sorted(results['style'].items()):
  print("  ", name)
  print("    shape: ", output.numpy().shape)
  print("    min: ", output.numpy().min())
  print("    max: ", output.numpy().max())
  print("    mean: ", output.numpy().mean())
  print()

print("Contents:")
for name, output in sorted(results['user'].items()):
  print("  ", name)
  print("    shape: ", output.numpy().shape)
  print("    min: ", output.numpy().min())
  print("    max: ", output.numpy().max())
  print("    mean: ", output.numpy().mean())


#gradient descent 
style_targets = extractor(style_image)['style']
user_targets = extractor(user_image)['user']

#image to optimize
image = tf.Variable(user_image)

#keep pixel values between 0 and 1 
def clip_0_1(image):
  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)

#build an optimizer 
opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)

#weighted combination of losses 
style_weight=1e-2
user_weight=1e4

#calculate loss 
def style_content_loss(outputs):
    style_outputs = outputs['style']
    user_outputs = outputs['user']
    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) 
                           for name in style_outputs.keys()])
    style_loss *= style_weight / num_style_layers

    user_loss = tf.add_n([tf.reduce_mean((user_outputs[name]-user_targets[name])**2) 
                             for name in user_outputs.keys()])
    user_loss *= user_weight / num_user_layers
    loss = style_loss + user_loss
    return loss
  
#update the image 

@tf.function()
def train_step(image):
  with tf.GradientTape() as tape:
    outputs = extractor(image)
    loss = style_content_loss(outputs)

  grad = tape.gradient(loss, image)
  opt.apply_gradients([(grad, image)])
  image.assign(clip_0_1(image))

#optimization 
import time
start = time.time()

epochs = 10
steps_per_epoch = 100

#test 
train_step(image)
train_step(image)
train_step(image)
tensor_to_image(image)
  
end = time.time()
print("Total time: {:.1f}".format(end-start))

#total variation loss - sum of the square of the values 
def high_pass_x_y(image):
  x_var = image[:, :, 1:, :] - image[:, :, :-1, :]
  y_var = image[:, 1:, :, :] - image[:, :-1, :, :]

  return x_var, y_var

def total_variation_loss(image):
  x_deltas, y_deltas = high_pass_x_y(image)
  return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))

total_variation_loss(image).numpy() 

#tensor flow implementation 
tf.image.total_variation(image).numpy()

#weight for variation 
total_variation_weight=30

#new train 
@tf.function()
def train_step(image):
  with tf.GradientTape() as tape:
    outputs = extractor(image)
    loss = style_content_loss(outputs)
    loss += total_variation_weight*tf.image.total_variation(image)

  grad = tape.gradient(loss, image)
  opt.apply_gradients([(grad, image)])
  image.assign(clip_0_1(image))


#re run optimizer 
opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)
image = tf.Variable(user_image)

import time
start = time.time()

epochs = 10
steps_per_epoch = 100

step = 0

#test 
train_step(image)
train_step(image)
train_step(image)
tensor_to_image(image)

end = time.time()
print("Total time: {:.1f}".format(end-start))
